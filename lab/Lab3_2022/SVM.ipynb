{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear models: Support Vector Machines (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we are going to explore linear models and Support Vector Machines (SVM in short).\n",
    "\n",
    "Let's first import the required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put here your ``numero di matricola''\n",
    "numero_di_matricola = 2074282\n",
    "\n",
    "from sklearn import datasets, preprocessing, linear_model, svm\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM for linearly separable data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by creating a simple linearly separable dataset for binary classification, where the instance space is $\\mathcal{X} =\\mathbb{R}^2$ (so that we can visualize it). Just to make things easier, we are going to rescale it too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = datasets.make_blobs(n_samples = 500, centers = 2, n_features = 2, random_state=numero_di_matricola)\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code plots the dataset, it is useful for later parts too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Plot of dataset\")\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's run the perceptron, using $\\texttt{linear\\_model.Perceptron(...)}$ from sklearn. WE fix the number of iterations to 100 so that it runs quickly, and $\\texttt{random\\_state=10}$.\n",
    "\n",
    "What do we expect in terms of training error? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a perceptron classifier\n",
    "# TO DO: COMPLETE\n",
    "model_perceptron_1 = linear_model.Perceptron(max_iter=100, random_state=10)\n",
    "\n",
    "#Training the model\n",
    "# TO DO: COMPLETE\n",
    "model_perceptron_1.fit(X, y)\n",
    "\n",
    "#Get the training error as 1 - score()\n",
    "# TO DO: COMPLETE\n",
    "training_error = 1-model_perceptron_1.score(X, y)\n",
    "\n",
    "#Print the training error\n",
    "# TO DO: COMPLETE\n",
    "print(\"Training error: \", training_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code plots the *decision boundary* of a model and the training set. It is useful for later parts too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=30)\n",
    "ax = plt.gca()\n",
    "plt.title(\"Plot of perceptron decision boundary\")\n",
    "xlim = ax.get_xlim()\n",
    "ylim = ax.get_ylim()\n",
    "# create grid to evaluate model\n",
    "xx = np.linspace(xlim[0], xlim[1], 30)\n",
    "yy = np.linspace(ylim[0], ylim[1], 30)\n",
    "YY, XX = np.meshgrid(yy, xx)\n",
    "xy = np.vstack([XX.ravel(), YY.ravel()]).T\n",
    "# use the decision_function call to obtain the boundary to be plot.\n",
    "# TO DO\n",
    "\n",
    "Z = model_perceptron_1.decision_function(xy).reshape(XX.shape)\n",
    "\n",
    "# plot decision boundary and margins\n",
    "ax.contour(XX, YY, Z, colors='k', levels=[0], alpha=1,\n",
    "linestyles=['-'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we change the value of $\\texttt{random\\_state}$ in the perceptron, it will start from a different model. \n",
    "\n",
    "Let's run the perceptron with $\\texttt{random\\_state}=12$. How will the solution compare to the above?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a perceptron classifier\n",
    "# TO DO: COMPLETE\n",
    "model_perceptron_2 = linear_model.Perceptron(max_iter=100, random_state=12)\n",
    "\n",
    "#Training the model\n",
    "# TO DO: COMPLETE\n",
    "model_perceptron_2.fit(X, y)\n",
    "\n",
    "#Get the training error as 1 - score()\n",
    "# TO DO: COMPLETE\n",
    "training_error = 1-model_perceptron_2.score(X, y)\n",
    "\n",
    "#Print the training error\n",
    "# TO DO: COMPLETE\n",
    "print(\"Training error: \", training_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about the decision boundary? Let's plot it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: WRITE THE CODE TO PLOT THE DECISION BOUNDARY\n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=30)\n",
    "ax = plt.gca()\n",
    "plt.title(\"Plot of perceptron decision boundary\")\n",
    "xlim = ax.get_xlim()\n",
    "ylim = ax.get_ylim()\n",
    "# create grid to evaluate model\n",
    "xx = np.linspace(xlim[0], xlim[1], 30)\n",
    "yy = np.linspace(ylim[0], ylim[1], 30)\n",
    "YY, XX = np.meshgrid(yy, xx)\n",
    "xy = np.vstack([XX.ravel(), YY.ravel()]).T\n",
    "# use the decision_function call to obtain the boundary to be plot.\n",
    "# TO DO\n",
    "\n",
    "Z = model_perceptron_2.decision_function(xy).reshape(XX.shape)\n",
    "\n",
    "# plot decision boundary and margins\n",
    "ax.contour(XX, YY, Z, colors='k', levels=[0], alpha=1,\n",
    "linestyles=['-'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which model is better? \n",
    "\n",
    "Is any of these the *best* choice?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's run the hard-SVM on the same data. To obtain (an almost) hard-SVM in sklearn, we can use $\\texttt{svm.SVC(...)}$ with a very high value of the parameter $C$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a SVM model\n",
    "# TO DO: COMPLETE\n",
    "model_svm = svm.SVC(kernel=\"linear\" , C=100000000)\n",
    "\n",
    "#Training the model\n",
    "model_svm.fit(X, y)\n",
    "\n",
    "\n",
    "#Get the training error as 1 - score()\n",
    "training_error = 1 - model_svm.score(X , y)\n",
    "\n",
    "\n",
    "#Print the training error\n",
    "# TO DO: COMPLETE\n",
    "print(\"Training error: \", training_error)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the SVM decision boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: WRITE THE CODE TO PLOT THE DECISION BOUNDARY\n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=30)\n",
    "ax = plt.gca()\n",
    "plt.title(\"Plot of perceptron decision boundary\")\n",
    "xlim = ax.get_xlim()\n",
    "ylim = ax.get_ylim()\n",
    "# create grid to evaluate model\n",
    "xx = np.linspace(xlim[0], xlim[1], 30)\n",
    "yy = np.linspace(ylim[0], ylim[1], 30)\n",
    "YY, XX = np.meshgrid(yy, xx)\n",
    "xy = np.vstack([XX.ravel(), YY.ravel()]).T\n",
    "# use the decision_function call to obtain the boundary to be plot.\n",
    "# TO DO\n",
    "\n",
    "Z = model_svm.decision_function(xy).reshape(XX.shape)\n",
    "\n",
    "# plot decision boundary and margins\n",
    "ax.contour(XX, YY, Z, colors='k', levels=[0], alpha=1,\n",
    "linestyles=['-'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what the support vectors are. They are defined in attribute $\\texttt{support_vectors_}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the support vectors (attribute support)\n",
    "#TO DO: COMPLETE\n",
    "print(model_svm.support_vectors_)\n",
    "\n",
    "print(model_svm.dual_coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's what happens moving one support vector. We first obtain the indices of the support vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the indices of support vectors (attribute support)\n",
    "#TO DO: COMPLETE\n",
    "print(model_svm.support_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's move one support vector closer to the points in the same class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's copy the data and maove one support vector close to the points in the same class\n",
    "X1 = X.copy()\n",
    "\n",
    "X1[321 , 0] = -1\n",
    "\n",
    "#let's plot the new dataset\n",
    "#TO DO: COMPLETE\n",
    "plt.title(\"Plot of dataset\")\n",
    "plt.scatter(X1[:, 0], X1[:, 1], c=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run the SVM on the new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a SVM model\n",
    "# TO DO: COMPLETE\n",
    "model_svm_1 = svm.SVC(kernel=\"linear\" , C=100000000)\n",
    "\n",
    "#Training the model\n",
    "model_svm_1.fit(X1, y)\n",
    "\n",
    "\n",
    "#Get the training error as 1 - score()\n",
    "training_error = 1 - model_svm_1.score(X1 , y)\n",
    "\n",
    "\n",
    "#Print the training error\n",
    "# TO DO: COMPLETE\n",
    "print(\"Training error: \", training_error)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the SVM decision boundary and the previous decision boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: WRITE THE CODE TO PLOT THE DECISION BOUNDARY\n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=30)\n",
    "ax = plt.gca()\n",
    "plt.title(\"Plot of perceptron decision boundary\")\n",
    "xlim = ax.get_xlim()\n",
    "ylim = ax.get_ylim()\n",
    "# create grid to evaluate model\n",
    "xx = np.linspace(xlim[0], xlim[1], 30)\n",
    "yy = np.linspace(ylim[0], ylim[1], 30)\n",
    "YY, XX = np.meshgrid(yy, xx)\n",
    "xy = np.vstack([XX.ravel(), YY.ravel()]).T\n",
    "# use the decision_function call to obtain the boundary to be plot.\n",
    "# TO DO\n",
    "\n",
    "Z1 = model_svm_1.decision_function(xy).reshape(XX.shape)\n",
    "\n",
    "# plot decision boundary and margins\n",
    "ax.contour(XX, YY, Z1, colors='k', levels=[0], alpha=1,\n",
    "linestyles=['-'])\n",
    "ax.contour(XX, YY, Z, colors='b', levels=[0], alpha=1,\n",
    "linestyles=['-'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's move one support vector closer to the points in the otherr class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's copy the original data and move one support vector close to the points in the other class\n",
    "#TO DO: COMPLETE\n",
    "\n",
    "\n",
    "#let's plot the new dataset\n",
    "#TO DO: COMPLETE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run the SVM on the new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a SVM model\n",
    "# TO DO: COMPLETE\n",
    "\n",
    "\n",
    "#Training the model\n",
    "# TO DO: COMPLETE\n",
    "\n",
    "\n",
    "#Get the training error as 1 - score()\n",
    "# TO DO: COMPLETE\n",
    "\n",
    "\n",
    "#Print the training error\n",
    "# TO DO: COMPLETE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the new decision boundary, and the old ones too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: COMPLETE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM for non-linearly separable data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a dataset that is not linearly separable, and let's plot it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: COMPLETE\n",
    "\n",
    "X_nls, y_nls = datasets.make_blobs(n_samples = 500, centers = 2, n_features = 2, random_state=numero_di_matricola)\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(X_nls)\n",
    "X_nls = scaler.transform(X_nls)\n",
    "\n",
    "a = np.array([[0.3, 2]])\n",
    "b = np.array([0])\n",
    "X_nls = np.concatenate((X_nls, a))\n",
    "y_nls = np.concatenate((y_nls, b))\n",
    "\n",
    "a = np.array([[0.1, -1.5]])\n",
    "b = np.array([0])\n",
    "X_nls = np.concatenate((X_nls, a))\n",
    "y_nls = np.concatenate((y_nls, b))\n",
    "\n",
    "a = np.array([[0, 0.1]])\n",
    "b = np.array([1])\n",
    "X_nls = np.concatenate((X_nls, a))\n",
    "y_nls = np.concatenate((y_nls, b))\n",
    "\n",
    "plt.title(\"Plot of dataset\")\n",
    "plt.scatter(X_nls[:,0],X_nls[:,1], c = y_nls)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to learn a hard-SVM. It means that the parameter C, which is approximately equal to $1/\\lambda$ with $\\lambda$ as in our slides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a SVM model\n",
    "# TO DO: COMPLETE\n",
    "model_hard_svm = svm.SVC(kernel=\"linear\" , C=100000000)\n",
    "\n",
    "#Training the model\n",
    "model_hard_svm.fit(X_nls, y_nls)\n",
    "\n",
    "\n",
    "#Get the training error as 1 - score()\n",
    "training_error = 1 - model_hard_svm.score(X_nls , y_nls)\n",
    "\n",
    "\n",
    "#Print the training error\n",
    "# TO DO: COMPLETE\n",
    "print(\"Training error: \", training_error)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code plots the decision boundary, as well as the margin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_nls[:, 0], X_nls[:, 1], c=y_nls, s=30)\n",
    "ax = plt.gca()\n",
    "plt.title(\"Plot of hard SVM decision boundary\")\n",
    "xlim = ax.get_xlim()\n",
    "ylim = ax.get_ylim()\n",
    "# create grid to evaluate model\n",
    "xx = np.linspace(xlim[0], xlim[1], 30)\n",
    "yy = np.linspace(ylim[0], ylim[1], 30)\n",
    "YY, XX = np.meshgrid(yy, xx)\n",
    "xy = np.vstack([XX.ravel(), YY.ravel()]).T\n",
    "\n",
    "#TO DO\n",
    "Z = model_hard_svm.decision_function(xy).reshape(XX.shape)\n",
    "\n",
    "ax.contour(\n",
    "    XX, YY, Z, colors=\"k\", levels=[-1, 0, 1], alpha=0.5, linestyles=[\"--\", \"-\", \"--\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try with a smaller value of C ($10^4$), that corresponds to larger value of $\\lambda$.\n",
    "\n",
    "What do you expect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a SVM model\n",
    "# TO DO: COMPLETE\n",
    "model_hard_svm = svm.SVC(kernel=\"linear\" , C=10000)\n",
    "\n",
    "#Training the model\n",
    "model_hard_svm.fit(X_nls, y_nls)\n",
    "\n",
    "\n",
    "#Get the training error as 1 - score()\n",
    "training_error = 1 - model_hard_svm.score(X_nls , y_nls)\n",
    "\n",
    "\n",
    "#Print the training error\n",
    "# TO DO: COMPLETE\n",
    "print(\"Training error: \", training_error)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about the decision boundary and the margin?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_nls[:, 0], X_nls[:, 1], c=y_nls, s=30)\n",
    "ax = plt.gca()\n",
    "plt.title(\"Plot of hard SVM decision boundary\")\n",
    "xlim = ax.get_xlim()\n",
    "ylim = ax.get_ylim()\n",
    "# create grid to evaluate model\n",
    "xx = np.linspace(xlim[0], xlim[1], 30)\n",
    "yy = np.linspace(ylim[0], ylim[1], 30)\n",
    "YY, XX = np.meshgrid(yy, xx)\n",
    "xy = np.vstack([XX.ravel(), YY.ravel()]).T\n",
    "\n",
    "#TO DO\n",
    "Z = model_hard_svm.decision_function(xy).reshape(XX.shape)\n",
    "\n",
    "ax.contour(\n",
    "    XX, YY, Z, colors=\"k\", levels=[-1, 0, 1], alpha=0.5, linestyles=[\"--\", \"-\", \"--\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's repeat everything for C=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a hard SVM model\n",
    "# TO DO: COMPLETE\n",
    "model_hard_svm_3 = svm.SVC(kernel=\"linear\",C=100)\n",
    "\n",
    "#Training the model\n",
    "# TO DO: COMPLETE\n",
    "model_hard_svm_3.fit(X_nls, y_nls)\n",
    "\n",
    "#Get the training error as 1 - score()\n",
    "# TO DO: COMPLETE\n",
    "training_error = 1- model_hard_svm_3.score(X_nls,y_nls)\n",
    "\n",
    "#Print the training error\n",
    "# TO DO: COMPLETE\n",
    "print(\"Training error: \", training_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: COMPLETE\n",
    "\n",
    "plt.scatter(X_nls[:, 0], X_nls[:, 1], c=y_nls, s=30)\n",
    "ax = plt.gca()\n",
    "plt.title(\"Plot of hard SVM decision boundary\")\n",
    "xlim = ax.get_xlim()\n",
    "ylim = ax.get_ylim()\n",
    "# create grid to evaluate model\n",
    "xx = np.linspace(xlim[0], xlim[1], 30)\n",
    "yy = np.linspace(ylim[0], ylim[1], 30)\n",
    "YY, XX = np.meshgrid(yy, xx)\n",
    "xy = np.vstack([XX.ravel(), YY.ravel()]).T\n",
    "Z = model_hard_svm_3.decision_function(xy).reshape(XX.shape)\n",
    "# plot decision boundary and margins\n",
    "#ax.contour(XX, YY, Z, colors='k', levels=[0], alpha=1,\n",
    "#linestyles=['-'])\n",
    "ax.contour(\n",
    "    XX, YY, Z, colors=\"k\", levels=[-1, 0, 1], alpha=0.5, linestyles=[\"--\", \"-\", \"--\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And for C=1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a hard SVM model\n",
    "# TO DO: COMPLETE\n",
    "model_hard_svm_4 = svm.SVC(kernel=\"linear\",C=1)\n",
    "\n",
    "#Training the model\n",
    "# TO DO: COMPLETE\n",
    "model_hard_svm_4.fit(X_nls, y_nls)\n",
    "\n",
    "#Get the training error as 1 - score()\n",
    "# TO DO: COMPLETE\n",
    "training_error = 1- model_hard_svm_4.score(X_nls,y_nls)\n",
    "\n",
    "#Print the training error\n",
    "# TO DO: COMPLETE\n",
    "print(\"Training error: \", training_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: COMPLETE\n",
    "\n",
    "plt.scatter(X_nls[:, 0], X_nls[:, 1], c=y_nls, s=30)\n",
    "ax = plt.gca()\n",
    "plt.title(\"Plot of hard SVM decision boundary\")\n",
    "xlim = ax.get_xlim()\n",
    "ylim = ax.get_ylim()\n",
    "# create grid to evaluate model\n",
    "xx = np.linspace(xlim[0], xlim[1], 30)\n",
    "yy = np.linspace(ylim[0], ylim[1], 30)\n",
    "YY, XX = np.meshgrid(yy, xx)\n",
    "xy = np.vstack([XX.ravel(), YY.ravel()]).T\n",
    "Z = model_hard_svm_4.decision_function(xy).reshape(XX.shape)\n",
    "# plot decision boundary and margins\n",
    "#ax.contour(XX, YY, Z, colors='k', levels=[0], alpha=1,\n",
    "#linestyles=['-'])\n",
    "ax.contour(\n",
    "    XX, YY, Z, colors=\"k\", levels=[-1, 0, 1], alpha=0.5, linestyles=[\"--\", \"-\", \"--\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what are the support vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO DO COMPLETE:\n",
    "print(model_hard_svm_4.support_vectors_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just for comparison, let's run the perceptron on the same dataset with various initial random states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a perceptron classifier\n",
    "# TO DO: COMPLETE\n",
    "model_perceptron_nls = linear_model.Perceptron(max_iter=100, random_state = 0)\n",
    "\n",
    "#Training the model\n",
    "# TO DO: COMPLETE\n",
    "model_perceptron_nls.fit(X_nls, y_nls)\n",
    "\n",
    "#Get the training error as 1 - score()\n",
    "# TO DO: COMPLETE\n",
    "training_error = 1- model_perceptron_nls.score(X_nls,y_nls)\n",
    "\n",
    "#Print the training error\n",
    "# TO DO: COMPLETE\n",
    "print(\"Training error: \", training_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the decision boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: COMPLETE\n",
    "\n",
    "plt.scatter(X_nls[:, 0], X_nls[:, 1], c=y_nls, s=30)\n",
    "ax = plt.gca()\n",
    "plt.title(\"Plot of perceptron decision boundary\")\n",
    "xlim = ax.get_xlim()\n",
    "ylim = ax.get_ylim()\n",
    "# create grid to evaluate model\n",
    "xx = np.linspace(xlim[0], xlim[1], 30)\n",
    "yy = np.linspace(ylim[0], ylim[1], 30)\n",
    "YY, XX = np.meshgrid(yy, xx)\n",
    "xy = np.vstack([XX.ravel(), YY.ravel()]).T\n",
    "Z = model_perceptron_nls.decision_function(xy).reshape(XX.shape)\n",
    "# plot decision boundary and margins\n",
    "ax.contour(XX, YY, Z, colors='k', levels=[0], alpha=1,\n",
    "linestyles=['-'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a perceptron classifier\n",
    "# TO DO: COMPLETE\n",
    "model_perceptron_nls = linear_model.Perceptron(max_iter=100, random_state = 10)\n",
    "\n",
    "#Training the model\n",
    "# TO DO: COMPLETE\n",
    "model_perceptron_nls.fit(X_nls, y_nls)\n",
    "\n",
    "#Get the training error as 1 - score()\n",
    "# TO DO: COMPLETE\n",
    "training_error = 1- model_perceptron_nls.score(X_nls,y_nls)\n",
    "\n",
    "#Print the training error\n",
    "# TO DO: COMPLETE\n",
    "print(\"Training error: \", training_error)\n",
    "\n",
    "plt.scatter(X_nls[:, 0], X_nls[:, 1], c=y_nls, s=30)\n",
    "ax = plt.gca()\n",
    "plt.title(\"Plot of perceptron decision boundary\")\n",
    "xlim = ax.get_xlim()\n",
    "ylim = ax.get_ylim()\n",
    "# create grid to evaluate model\n",
    "xx = np.linspace(xlim[0], xlim[1], 30)\n",
    "yy = np.linspace(ylim[0], ylim[1], 30)\n",
    "YY, XX = np.meshgrid(yy, xx)\n",
    "xy = np.vstack([XX.ravel(), YY.ravel()]).T\n",
    "Z = model_perceptron_nls.decision_function(xy).reshape(XX.shape)\n",
    "# plot decision boundary and margins\n",
    "ax.contour(XX, YY, Z, colors='k', levels=[0], alpha=1,\n",
    "linestyles=['-'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a perceptron classifier\n",
    "# TO DO: COMPLETE\n",
    "model_perceptron_nls = linear_model.Perceptron(max_iter=100, random_state = 24)\n",
    "\n",
    "#Training the model\n",
    "# TO DO: COMPLETE\n",
    "model_perceptron_nls.fit(X_nls, y_nls)\n",
    "\n",
    "#Get the training error as 1 - score()\n",
    "# TO DO: COMPLETE\n",
    "training_error = 1- model_perceptron_nls.score(X_nls,y_nls)\n",
    "\n",
    "#Print the training error\n",
    "# TO DO: COMPLETE\n",
    "print(\"Training error: \", training_error)\n",
    "\n",
    "plt.scatter(X_nls[:, 0], X_nls[:, 1], c=y_nls, s=30)\n",
    "ax = plt.gca()\n",
    "plt.title(\"Plot of perceptron decision boundary\")\n",
    "xlim = ax.get_xlim()\n",
    "ylim = ax.get_ylim()\n",
    "# create grid to evaluate model\n",
    "xx = np.linspace(xlim[0], xlim[1], 30)\n",
    "yy = np.linspace(ylim[0], ylim[1], 30)\n",
    "YY, XX = np.meshgrid(yy, xx)\n",
    "xy = np.vstack([XX.ravel(), YY.ravel()]).T\n",
    "Z = model_perceptron_nls.decision_function(xy).reshape(XX.shape)\n",
    "# plot decision boundary and margins\n",
    "ax.contour(XX, YY, Z, colors='k', levels=[0], alpha=1,\n",
    "linestyles=['-'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "d6130dc0ca154d48d4309febcf6869dce2f08df7913a461d2bad8c19ec3dd616"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
